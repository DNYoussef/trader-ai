"""
Black Swan Strategy Toolbox - Production Implementation
Collection of 8 strategies optimized for capturing tail events with convex payoffs

Each strategy is designed to:
1. Have limited downside (max loss capped)
2. Capture explosive upside during black swan events
3. Generate positive convexity (asymmetric risk/reward)
"""

import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime
from decimal import Decimal, ROUND_HALF_UP
from abc import ABC, abstractmethod
import sqlite3
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class StrategySignal:
    """Signal generated by a strategy"""
    strategy_name: str
    timestamp: datetime
    symbol: str
    action: str  # 'buy', 'sell', 'hold'
    confidence: float  # 0-1
    expected_return: float
    max_downside: float
    convexity_ratio: float  # upside/downside ratio
    allocation_pct: Decimal
    stop_loss: float
    take_profit: float
    time_horizon_days: int
    reasoning: str
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class MarketState:
    """Current market conditions"""
    timestamp: datetime
    vix_level: float
    vix_percentile: float
    spy_returns_5d: float
    spy_returns_20d: float
    put_call_ratio: float
    market_breadth: float  # % of stocks above MA
    correlation: float  # average pairwise correlation
    volume_ratio: float  # current vs 20d average
    regime: str  # 'calm', 'normal', 'volatile', 'crisis'
    indicators: Dict[str, float] = field(default_factory=dict)

class BaseStrategy(ABC):
    """Abstract base class for all strategies"""

    def __init__(self, name: str, max_position_pct: float = 0.05):
        self.name = name
        self.max_position_pct = max_position_pct
        self.position_history: List[StrategySignal] = []
        self.performance_metrics = {
            'total_trades': 0,
            'winning_trades': 0,
            'total_return': 0.0,
            'max_drawdown': 0.0,
            'sharpe_ratio': 0.0,
            'convexity_achieved': []
        }

    @abstractmethod
    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        """Analyze market and generate signal"""
        pass

    def calculate_position_size(self, confidence: float, volatility: float) -> Decimal:
        """Calculate position size based on confidence and volatility"""
        # Kelly-inspired sizing with safety factor
        base_size = Decimal(str(self.max_position_pct))
        confidence_factor = Decimal(str(confidence))
        vol_adjustment = Decimal(str(max(0.5, 1.0 - volatility)))

        position_size = base_size * confidence_factor * vol_adjustment
        position_size = position_size.quantize(Decimal('0.0001'), ROUND_HALF_UP)

        return min(position_size, Decimal(str(self.max_position_pct)))

    def update_performance(self, signal: StrategySignal, actual_return: float):
        """Update strategy performance metrics"""
        self.performance_metrics['total_trades'] += 1
        if actual_return > 0:
            self.performance_metrics['winning_trades'] += 1

        self.performance_metrics['total_return'] += actual_return

        # Track convexity achieved
        if signal.max_downside != 0:
            achieved_convexity = actual_return / abs(signal.max_downside)
            self.performance_metrics['convexity_achieved'].append(achieved_convexity)

class TailHedgeStrategy(BaseStrategy):
    """
    Strategy 1: Tail Hedging
    Buys deep out-of-the-money puts when they're cheap
    Profits massively during market crashes
    """

    def __init__(self):
        super().__init__("tail_hedge", max_position_pct=0.02)
        self.vix_threshold = 20  # Buy protection when VIX is elevated but not extreme
        self.put_strike_pct = 0.90  # 10% OTM puts

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Check if volatility is elevated (good time for tail protection)
        if market_state.vix_level < self.vix_threshold:
            return None

        # Check if market is complacent (low recent volatility) - relaxed threshold
        if market_state.vix_percentile > 0.5:
            return None

        # Add volume confirmation - elevated volume suggests institutional activity
        if market_state.volume_ratio < 1.2:
            return None

        # Check for potential catalysts
        days_since_correction = self._days_since_last_correction(historical_data)
        if days_since_correction < 60:
            return None

        # Calculate expected payoff
        confidence = 0.7 if days_since_correction > 180 else 0.5
        expected_return = 5.0 if market_state.vix_level < 12 else 3.0  # 3-5x on crash
        max_downside = -0.02  # Premium paid for puts

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol='SPY_PUT',
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, market_state.vix_level / 100),
            stop_loss=0.0,  # No stop on hedges
            take_profit=expected_return * 0.8,
            time_horizon_days=30,
            reasoning=f"VIX at {market_state.vix_level:.1f} (cheap protection), "
                     f"{days_since_correction} days since correction"
        )

    def _days_since_last_correction(self, historical_data: pd.DataFrame) -> int:
        """Calculate days since last 5% correction"""
        if historical_data.empty:
            return 0

        # Calculate rolling max and drawdowns
        spy_data = historical_data[historical_data['symbol'] == 'SPY'].copy()
        if spy_data.empty:
            return 0

        spy_data['cummax'] = spy_data['close'].cummax()
        spy_data['drawdown'] = (spy_data['close'] - spy_data['cummax']) / spy_data['cummax']

        # Find last correction
        corrections = spy_data[spy_data['drawdown'] <= -0.05]
        if corrections.empty:
            return len(spy_data)

        last_correction_date = pd.to_datetime(corrections.iloc[-1]['date'])
        current_date = pd.to_datetime(spy_data.iloc[-1]['date'])
        return (current_date - last_correction_date).days

class VolatilityHarvestStrategy(BaseStrategy):
    """
    Strategy 2: Volatility Harvesting
    Goes long volatility before known events or when term structure inverts
    """

    def __init__(self):
        super().__init__("volatility_harvest", max_position_pct=0.03)
        self.contango_threshold = -0.02  # Backwardation signal (more sensitive)

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Check for volatility term structure inversion (backwardation)
        term_structure = market_state.indicators.get('vix_term_structure', 0)

        if term_structure > self.contango_threshold:
            return None  # Not in backwardation

        # Add VIX level confirmation for volatility harvest
        if market_state.vix_level < 18:  # Need some base volatility
            return None

        # Check for clustering (volatility begets volatility)
        recent_volatility = self._calculate_volatility_cluster(historical_data)
        if recent_volatility < 0.02:  # Not volatile enough
            return None

        confidence = min(0.8, 0.5 + abs(term_structure) * 2)
        expected_return = 0.5 + abs(term_structure) * 5  # 50-100% potential
        max_downside = -0.15  # VIX can decay quickly

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol='VIXY',  # VIX ETF
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, market_state.vix_level / 100),
            stop_loss=max_downside * 0.8,
            take_profit=expected_return * 0.7,
            time_horizon_days=10,
            reasoning=f"VIX term structure in backwardation ({term_structure:.2f}), "
                     f"volatility clustering detected"
        )

    def _calculate_volatility_cluster(self, historical_data: pd.DataFrame) -> float:
        """Calculate recent volatility clustering"""
        if historical_data.empty:
            return 0

        spy_data = historical_data[historical_data['symbol'] == 'SPY'].tail(20)
        if len(spy_data) < 5:
            return 0

        returns = spy_data['returns'].values
        return np.std(returns)

class CrisisAlphaStrategy(BaseStrategy):
    """
    Strategy 3: Crisis Alpha
    Predetermined playbook for crisis situations
    Goes long safe havens (gold, bonds) and short risk assets
    """

    def __init__(self):
        super().__init__("crisis_alpha", max_position_pct=0.10)
        self.crisis_vix_threshold = 25
        self.safe_havens = ['GLD', 'TLT', 'UUP']
        self.risk_assets = ['SPY', 'QQQ', 'IWM']

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Check if we're in crisis mode
        if market_state.vix_level < self.crisis_vix_threshold:
            return None

        # Check market breadth (widespread selling) - relaxed threshold
        if market_state.market_breadth > 0.4:  # More lenient for crisis detection
            return None

        # Add put/call ratio confirmation for crisis
        if market_state.put_call_ratio < 1.0:  # Not enough fear
            return None

        # Determine which safe haven to buy
        best_haven = self._select_best_haven(historical_data)

        confidence = min(0.9, 0.5 + (market_state.vix_level - 30) / 100)
        expected_return = 0.2 + (market_state.vix_level - 30) / 50  # 20-60%
        max_downside = -0.05  # Safe havens have limited downside in crisis

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol=best_haven,
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, 0.5),  # Large position in crisis
            stop_loss=max_downside * 2,
            take_profit=expected_return * 0.8,
            time_horizon_days=20,
            reasoning=f"Crisis mode activated (VIX={market_state.vix_level:.1f}), "
                     f"buying safe haven {best_haven}"
        )

    def _select_best_haven(self, historical_data: pd.DataFrame) -> str:
        """Select best performing safe haven"""
        best_haven = 'GLD'  # Default to gold
        best_performance = -1.0

        for haven in self.safe_havens:
            haven_data = historical_data[historical_data['symbol'] == haven].tail(5)
            if not haven_data.empty:
                recent_return = haven_data['returns'].sum()
                if recent_return > best_performance:
                    best_performance = recent_return
                    best_haven = haven

        return best_haven

class MomentumExplosionStrategy(BaseStrategy):
    """
    Strategy 4: Momentum Explosion
    Detects and rides parabolic moves early
    Uses trailing stops to capture black swan melt-ups
    """

    def __init__(self):
        super().__init__("momentum_explosion", max_position_pct=0.05)
        self.momentum_threshold = 0.05  # 5% move in 5 days
        self.volume_spike = 1.2  # 1.2x average volume (realistic threshold)

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Find stocks with explosive momentum
        momentum_stocks = self._find_momentum_explosions(historical_data)

        if not momentum_stocks:
            return None

        best_stock = momentum_stocks[0]
        symbol = best_stock['symbol']
        momentum = best_stock['momentum']
        volume_ratio = best_stock['volume_ratio']

        confidence = min(0.8, 0.4 + momentum * 2)
        expected_return = momentum * 3  # Expect continuation
        max_downside = -0.10  # Use tight stops

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol=symbol,
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, momentum),
            stop_loss=max_downside,
            take_profit=expected_return,
            time_horizon_days=10,
            reasoning=f"Momentum explosion in {symbol}: {momentum:.1%} move, "
                     f"{volume_ratio:.1f}x volume"
        )

    def _find_momentum_explosions(self, historical_data: pd.DataFrame) -> List[Dict]:
        """Find stocks with explosive momentum"""
        explosions = []

        for symbol in historical_data['symbol'].unique():
            symbol_data = historical_data[historical_data['symbol'] == symbol].tail(20)

            if len(symbol_data) < 5:
                continue

            # Calculate 5-day momentum
            recent_data = symbol_data.tail(5)
            momentum = recent_data['returns'].sum()

            # Check volume spike
            if 'volume' in symbol_data.columns:
                recent_volume = recent_data['volume'].mean()
                avg_volume = symbol_data['volume'].mean()
                volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1
            else:
                volume_ratio = 1

            # Add momentum confirmation with realistic volume requirement
            if momentum > self.momentum_threshold and volume_ratio > self.volume_spike:
                explosions.append({
                    'symbol': symbol,
                    'momentum': momentum,
                    'volume_ratio': volume_ratio
                })

        # Sort by momentum
        explosions.sort(key=lambda x: x['momentum'], reverse=True)
        return explosions[:3]  # Top 3

class MeanReversionStrategy(BaseStrategy):
    """
    Strategy 5: Mean Reversion
    Trades extreme oversold conditions with tight risk management
    Small consistent gains with occasional large wins
    """

    def __init__(self):
        super().__init__("mean_reversion", max_position_pct=0.03)
        self.oversold_threshold = -2.0  # -2 sigma move
        self.rsi_threshold = 20

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Find extremely oversold stocks
        oversold_stocks = self._find_oversold_extremes(historical_data)

        if not oversold_stocks:
            return None

        best_stock = oversold_stocks[0]
        symbol = best_stock['symbol']
        sigma_move = best_stock['sigma_move']
        rsi = best_stock.get('rsi', 30)

        # Don't catch falling knives in crisis
        if market_state.regime == 'crisis':
            return None

        confidence = min(0.7, 0.3 + abs(sigma_move) * 0.1)
        expected_return = abs(sigma_move) * 0.3  # Expect 30% mean reversion
        max_downside = -0.05  # Tight stop

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol=symbol,
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, abs(sigma_move) / 10),
            stop_loss=max_downside,
            take_profit=expected_return * 0.7,
            time_horizon_days=5,
            reasoning=f"{symbol} oversold at {sigma_move:.1f} sigma, RSI={rsi:.0f}"
        )

    def _find_oversold_extremes(self, historical_data: pd.DataFrame) -> List[Dict]:
        """Find extremely oversold stocks"""
        oversold = []

        for symbol in historical_data['symbol'].unique():
            symbol_data = historical_data[historical_data['symbol'] == symbol].tail(60)

            if len(symbol_data) < 20:
                continue

            # Calculate sigma move
            recent_return = symbol_data.iloc[-1]['returns']
            mean_return = symbol_data['returns'].mean()
            std_return = symbol_data['returns'].std()

            if std_return > 0:
                sigma_move = (recent_return - mean_return) / std_return
            else:
                continue

            # Calculate RSI if available
            if 'rsi_14' in symbol_data.columns:
                rsi = symbol_data.iloc[-1]['rsi_14']
            else:
                rsi = 50

            if sigma_move <= self.oversold_threshold and rsi < self.rsi_threshold:
                oversold.append({
                    'symbol': symbol,
                    'sigma_move': sigma_move,
                    'rsi': rsi
                })

        # Sort by most oversold
        oversold.sort(key=lambda x: x['sigma_move'])
        return oversold[:3]

class CorrelationBreakdownStrategy(BaseStrategy):
    """
    Strategy 6: Correlation Breakdown
    Profits when normal correlations break
    Pairs trading with protective stops
    """

    def __init__(self):
        super().__init__("correlation_breakdown", max_position_pct=0.04)
        self.correlation_threshold = 0.7  # Minimum historical correlation
        self.deviation_threshold = 2.0  # 2 std deviation spread

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Find correlation breakdowns
        broken_pairs = self._find_correlation_breakdowns(historical_data)

        if not broken_pairs:
            return None

        best_pair = broken_pairs[0]
        long_symbol = best_pair['long']
        short_symbol = best_pair['short']
        spread_sigma = best_pair['spread_sigma']

        confidence = min(0.7, 0.4 + abs(spread_sigma - 2) * 0.2)
        expected_return = abs(spread_sigma) * 0.15  # Expect 15% per sigma of convergence
        max_downside = -0.03  # Pairs trading has limited risk

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol=f"{long_symbol}/{short_symbol}",
            action='buy',  # Buy the spread
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, spread_sigma / 10),
            stop_loss=max_downside * 1.5,
            take_profit=expected_return * 0.8,
            time_horizon_days=15,
            reasoning=f"Pair trade: Long {long_symbol}, Short {short_symbol}, "
                     f"spread at {spread_sigma:.1f} sigma"
        )

    def _find_correlation_breakdowns(self, historical_data: pd.DataFrame) -> List[Dict]:
        """Find pairs with broken correlations"""
        breakdowns = []
        symbols = historical_data['symbol'].unique()

        # Check common pairs
        pairs = [
            ('SPY', 'QQQ'),
            ('GLD', 'SLV'),
            ('TLT', 'IEF'),
            ('XLF', 'BAC'),
            ('XLE', 'XOM')
        ]

        for symbol1, symbol2 in pairs:
            if symbol1 not in symbols or symbol2 not in symbols:
                continue

            data1 = historical_data[historical_data['symbol'] == symbol1].tail(60)
            data2 = historical_data[historical_data['symbol'] == symbol2].tail(60)

            if len(data1) < 30 or len(data2) < 30:
                continue

            # Merge on date
            merged = pd.merge(
                data1[['date', 'returns']],
                data2[['date', 'returns']],
                on='date',
                suffixes=('_1', '_2')
            )

            if len(merged) < 30:
                continue

            # Calculate correlation
            correlation = merged['returns_1'].corr(merged['returns_2'])

            if correlation < self.correlation_threshold:
                continue

            # Calculate spread
            spread = merged['returns_1'] - merged['returns_2']
            spread_mean = spread.mean()
            spread_std = spread.std()

            if spread_std > 0:
                current_spread = spread.iloc[-1]
                spread_sigma = (current_spread - spread_mean) / spread_std

                if abs(spread_sigma) > self.deviation_threshold:
                    # Determine which to long/short
                    if spread_sigma > 0:
                        long_sym, short_sym = symbol2, symbol1
                    else:
                        long_sym, short_sym = symbol1, symbol2

                    breakdowns.append({
                        'long': long_sym,
                        'short': short_sym,
                        'correlation': correlation,
                        'spread_sigma': abs(spread_sigma)
                    })

        # Sort by spread deviation
        breakdowns.sort(key=lambda x: x['spread_sigma'], reverse=True)
        return breakdowns[:2]

class InequalityArbitrageStrategy(BaseStrategy):
    """
    Strategy 7: Inequality Arbitrage (Gary's Special)
    Trades wealth concentration effects
    Long luxury, short discount when inequality accelerates
    """

    def __init__(self):
        super().__init__("inequality_arbitrage", max_position_pct=0.05)
        self.luxury_stocks = ['LVMH', 'RACE', 'RCL', 'MAR']
        self.discount_stocks = ['WMT', 'DG', 'DLTR', 'FIVE']

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Check inequality indicators
        wealth_concentration = market_state.indicators.get('wealth_concentration', 0.5)
        wage_growth = market_state.indicators.get('real_wage_growth', 0)

        # Look for accelerating inequality
        if wealth_concentration < 0.6 or wage_growth > -0.02:
            return None

        # Calculate luxury vs discount performance
        lux_perf, disc_perf = self._calculate_sector_performance(historical_data)

        if lux_perf - disc_perf < 0.05:  # Not enough divergence yet
            return None

        confidence = min(0.8, 0.5 + wealth_concentration)
        expected_return = 0.3  # 30% on inequality trades
        max_downside = -0.08

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol='XRT/WMT',  # Retail vs Walmart spread
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, 0.3),
            stop_loss=max_downside,
            take_profit=expected_return * 0.8,
            time_horizon_days=60,
            reasoning=f"Inequality arbitrage: wealth concentration={wealth_concentration:.2f}, "
                     f"luxury outperforming by {(lux_perf - disc_perf):.1%}"
        )

    def _calculate_sector_performance(self, historical_data: pd.DataFrame) -> Tuple[float, float]:
        """Calculate luxury vs discount performance"""
        # Simplified - in production would track actual luxury/discount stocks
        spy_data = historical_data[historical_data['symbol'] == 'SPY'].tail(20)
        if spy_data.empty:
            return 0, 0

        # Use SPY as proxy for luxury, IWM for discount (simplified)
        iwm_data = historical_data[historical_data['symbol'] == 'IWM'].tail(20)

        lux_perf = spy_data['returns'].sum() if not spy_data.empty else 0
        disc_perf = iwm_data['returns'].sum() if not iwm_data.empty else 0

        return lux_perf, disc_perf

class EventCatalystStrategy(BaseStrategy):
    """
    Strategy 8: Event Catalyst
    Positions ahead of known catalysts with asymmetric payoffs
    Fed meetings, earnings, economic data
    """

    def __init__(self):
        super().__init__("event_catalyst", max_position_pct=0.04)
        self.event_vol_premium = 0.2  # Required vol premium

    def analyze(self, market_state: MarketState, historical_data: pd.DataFrame) -> Optional[StrategySignal]:
        # Check for upcoming catalysts
        days_to_fomc = market_state.indicators.get('days_to_fomc', 999)
        days_to_cpi = market_state.indicators.get('days_to_cpi', 999)
        days_to_earnings = market_state.indicators.get('days_to_earnings', 999)

        # Find nearest catalyst
        nearest_event = min(days_to_fomc, days_to_cpi, days_to_earnings)

        if nearest_event > 5 or nearest_event < 1:
            return None  # Too far or too close

        # Check if volatility is underpricing the event
        implied_vol = market_state.vix_level / 100 * np.sqrt(nearest_event / 365)
        historical_vol = self._calculate_event_volatility(historical_data, nearest_event)

        if implied_vol > historical_vol * (1 + self.event_vol_premium):
            return None  # Event already priced in

        confidence = 0.6
        expected_return = (historical_vol / implied_vol - 1) if implied_vol > 0 else 0.2
        max_downside = -0.04

        event_type = 'FOMC' if nearest_event == days_to_fomc else 'CPI' if nearest_event == days_to_cpi else 'Earnings'

        return StrategySignal(
            strategy_name=self.name,
            timestamp=market_state.timestamp,
            symbol='SPY_STRADDLE',
            action='buy',
            confidence=confidence,
            expected_return=expected_return,
            max_downside=max_downside,
            convexity_ratio=abs(expected_return / max_downside),
            allocation_pct=self.calculate_position_size(confidence, implied_vol),
            stop_loss=max_downside,
            take_profit=expected_return,
            time_horizon_days=nearest_event,
            reasoning=f"{event_type} in {nearest_event} days, "
                     f"implied vol {implied_vol:.1%} vs historical {historical_vol:.1%}"
        )

    def _calculate_event_volatility(self, historical_data: pd.DataFrame, days: int) -> float:
        """Calculate historical volatility around events"""
        spy_data = historical_data[historical_data['symbol'] == 'SPY'].tail(252)
        if len(spy_data) < 20:
            return 0.02  # Default 2% vol

        # Calculate rolling volatility
        returns = spy_data['returns'].values
        vol = np.std(returns) * np.sqrt(252)
        return vol

class BlackSwanStrategyToolbox:
    """
    Collection of all 8 strategies with orchestration logic
    Manages strategy selection and portfolio allocation
    """

    def __init__(self, portfolio_manager=None, market_data_provider=None):
        self.portfolio_manager = portfolio_manager
        self.market_data = market_data_provider

        # Initialize all strategies
        self.strategies = {
            'tail_hedge': TailHedgeStrategy(),
            'volatility_harvest': VolatilityHarvestStrategy(),
            'crisis_alpha': CrisisAlphaStrategy(),
            'momentum_explosion': MomentumExplosionStrategy(),
            'mean_reversion': MeanReversionStrategy(),
            'correlation_breakdown': CorrelationBreakdownStrategy(),
            'inequality_arbitrage': InequalityArbitrageStrategy(),
            'event_catalyst': EventCatalystStrategy()
        }

        # Strategy weights (will be optimized by backtesting)
        self.strategy_weights = {
            'tail_hedge': 0.15,
            'volatility_harvest': 0.10,
            'crisis_alpha': 0.20,
            'momentum_explosion': 0.15,
            'mean_reversion': 0.10,
            'correlation_breakdown': 0.10,
            'inequality_arbitrage': 0.15,
            'event_catalyst': 0.05
        }

        self.db_path = Path("data/black_swan_training.db")
        logger.info(f"BlackSwanStrategyToolbox initialized with {len(self.strategies)} strategies")

    def analyze_all_strategies(self, market_state: MarketState, historical_data: pd.DataFrame) -> List[StrategySignal]:
        """Run all strategies and collect signals"""
        signals = []

        for strategy_name, strategy in self.strategies.items():
            try:
                signal = strategy.analyze(market_state, historical_data)
                if signal:
                    # Apply strategy weight
                    signal.allocation_pct *= Decimal(str(self.strategy_weights[strategy_name]))
                    signals.append(signal)
                    logger.info(f"{strategy_name} generated signal: {signal.action} {signal.symbol}")
            except Exception as e:
                logger.error(f"Error in {strategy_name}: {e}")

        return signals

    def select_best_strategies(self, signals: List[StrategySignal], max_strategies: int = 3) -> List[StrategySignal]:
        """Select best strategies based on convexity and confidence"""
        if not signals:
            return []

        # Score each signal
        for signal in signals:
            signal.metadata['score'] = (
                signal.confidence * 0.3 +
                min(signal.convexity_ratio / 20, 1.0) * 0.5 +
                (1.0 - abs(signal.max_downside)) * 0.2
            )

        # Sort by score
        signals.sort(key=lambda x: x.metadata['score'], reverse=True)

        # Return top N
        return signals[:max_strategies]

    def update_strategy_weights(self, performance_data: Dict[str, float]):
        """Update strategy weights based on performance"""
        total_performance = sum(max(0, p) for p in performance_data.values())

        if total_performance > 0:
            for strategy_name in self.strategy_weights:
                if strategy_name in performance_data:
                    # Increase weight for profitable strategies
                    performance = max(0, performance_data[strategy_name])
                    self.strategy_weights[strategy_name] = 0.1 + (performance / total_performance) * 0.4

        # Normalize weights
        total_weight = sum(self.strategy_weights.values())
        if total_weight > 0:
            for strategy_name in self.strategy_weights:
                self.strategy_weights[strategy_name] /= total_weight

        self._save_weights_to_db()

    def _save_weights_to_db(self):
        """Save strategy weights to database"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            for strategy_name, weight in self.strategy_weights.items():
                cursor.execute('''
                    INSERT OR REPLACE INTO strategy_weights
                    (date, strategy_name, weight, optimization_metric)
                    VALUES (?, ?, ?, ?)
                ''', (datetime.now().isoformat(), strategy_name, weight, 0.0))
            conn.commit()

    def get_portfolio_allocation(self) -> Dict[str, float]:
        """Get current portfolio allocation across strategies"""
        allocation = {}
        for strategy_name, weight in self.strategy_weights.items():
            allocation[strategy_name] = weight * 0.20  # 20% of portfolio for aggressive strategies
        return allocation


if __name__ == "__main__":
    # Test the strategy toolbox
    import sys
    sys.path.append('.')

    # Create market state
    market_state = MarketState(
        timestamp=datetime.now(),
        vix_level=18.5,
        vix_percentile=0.4,
        spy_returns_5d=-0.03,
        spy_returns_20d=0.02,
        put_call_ratio=1.2,
        market_breadth=0.45,
        correlation=0.65,
        volume_ratio=1.3,
        regime='normal'
    )

    # Create toolbox
    toolbox = BlackSwanStrategyToolbox()

    # Load some historical data
    historical_data = pd.DataFrame()  # Would load from database

    # Analyze
    signals = toolbox.analyze_all_strategies(market_state, historical_data)
    best_signals = toolbox.select_best_strategies(signals)

    print(f"Generated {len(signals)} signals")
    for signal in best_signals:
        print(f"  {signal.strategy_name}: {signal.action} {signal.symbol} "
              f"(convexity={signal.convexity_ratio:.1f}x)")